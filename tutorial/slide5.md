# 진행척도
6장 완료

#
cnn이 잘 학습했는지 확인해보려고 adversal attack이라는걸 해볼수있는데.
그냥 노이즈 인젝션 좀 주고 결과 돌려보는거다.

pretrained모델로 이러한 결과를 봤음에도

그니까 일반화 에러와 샘플 에러 격차가 메우 큰걸 보여준다.

육안으로 봤을때는 구별 가능한 정도의 노이즈가 모델에게는 치명적인 오류 발생이 가능할것이다.

그러한 노이즈도 학습을 해놓아야 일반화 성능을 올릴수있을것이라 생각한다.
